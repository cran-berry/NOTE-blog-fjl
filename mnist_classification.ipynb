{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Read MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_MNIST = r\"https://github.com/amplab/datascience-sp14/raw/master/lab7/mldata/mnist-original.mat\"\n",
    "PATH_MNIST = r\"E:\\jupyter_code\\datasets\\mldata\"\n",
    "# def fetch(url_mnist=URL_MNIST, path_mnist=PATH_MNIST):\n",
    "#     if not os.path.isdir(PATH_MINST):\n",
    "#         os.makedirs(PATH_MINST)\n",
    "#     FILE_PATH = os.path.join(PATH_MINST, \"mnist-original.mat\")\n",
    "#     urllib.request.urlretrieve(URL_MNIST, FILE_PATH)\n",
    "\n",
    "# from sklearn.datasets.base import get_data_home\n",
    "# print(get_data_home())\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.datasets.base import get_data_home, load_data\n",
    "FILE_PATH = r\"E:\\jupyter_code\\datasets\"\n",
    "digits = fetch_mldata(\"MNIST original\", data_home=FILE_PATH)\n",
    "# print(digits.data.shape)\n",
    "# temp = digits.data[0].reshape(28, 28)\n",
    "# plt.matshow(temp, cmap=plt.cm.gray_r)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = digits.data, digits.target\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "permute = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[permute], y_train[permute]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分数据\n",
    "y_train_5, y_test_5 = (y_train == 5), (y_test == 5)\n",
    "# SGD 分类\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_clf = SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "sgd_clf.fit(X_train, y_train_5)\n",
    "# 交叉验证\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评价模型\n",
    "# T:True, F:False, P:Positive, N:Negative\n",
    "# recall = TP / (TP + FN)  在逃犯信息检索系统中，更希望尽可能地少漏掉逃犯，此时，就要提高召回率（查全率）\n",
    "# precision = TP / (TP + FP)  商品推荐系统中，为了尽可能地少打扰用户，更希望推荐内容确实是用户感兴趣的，就要提高精度（查准率）\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "precision = precision_score(y_train_pred, y_train_5)\n",
    "recall = recall_score(y_train_pred, y_train_5)\n",
    "f1 = f1_score(y_train_pred, y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不同 thresholds 下，precision, recall 的变化曲线\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, precision_recall_curve\n",
    "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=5, n_jobs=-1, method=\"decision_function\")\n",
    "precision, recall, thresholds = precision_recall_curve(y_train_5, y_scores)\n",
    "\n",
    "plt.plot(thresholds, precision[:-1], \"b--\", label=\"Precision\")\n",
    "plt.plot(thresholds, recall[:-1], \"g-\", label=\"Recall\")\n",
    "plt.xlabel(\"Thresholds\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC 曲线，AUC 面积\n",
    "fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)\n",
    "auc(fpr, tpr)\n",
    "roc_auc_score(y_train_5, y_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多分类\n",
    "#### OVR： 把某个类别的样本归为一类,其他剩余的样本归为另一类，构造出了k个SVM。将未知样本分类为具有最大分类函数值的那类。\n",
    "#### 优点： 训练k个分类器，个数较少，其分类速度相对较快。\n",
    "#### 缺点： 每个分类器的训练都是将全部的样本作为训练样本，这样在求解二次规划问题时，训练速度会随着训练样本的数量的增加而急剧减慢；\n",
    "#### 负类样本要远远大于正类样本，出现样本不对称，且随着训练数据的增加而趋向严重。可以引入不同的惩罚因子，较少的正类采用较大的惩罚因子C；\n",
    "#### 还有就是当有新的类别加进来时，需要对所有的模型进行重新训练。\n",
    "#### 衍生： 决策树\n",
    "#### OVO： 在任意两类样本之间设计一个SVM，k个类别的样本需要k(k-1)/2个SVM。对未知样本分类时得票最多的类别为该未知样本的类别。\n",
    "#### 注： 仅使用这两类样本。\n",
    "#### 优点： 不需要重新训练所有的SVM，只需要重新训练和增加语音样本相关的分类器。在训练单个模型时，相对速度较快。\n",
    "#### 缺点： 所需构造和测试的二值分类器的数量关于k成二次函数增长，总训练时间和测试时间相对较慢。\n",
    "#### 衍生： 有向无环图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_clf = SGDClassifier(max_iter=100, tol=1e-3)  # hinge: SVM\n",
    "sgd_clf.fit(X_train, y_train)  # OVO: SVM 对大数据支持不好\n",
    "# 预测\n",
    "predict = sgd_clf.predict([X[62000]])\n",
    "score = sgd_clf.decision_function([X[62000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交叉验证\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "X_train_scale = StandardScaler().fit_transform(X_train.astype(np.float64))\n",
    "cross_val_score(sgd_clf, X_train_scale, y_train, scoring=\"accuracy\", cv=4, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 错误分析： 混淆矩阵法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第 i 行第 j 列的数字代表数字 i 被预测为数字 j 的个数总和\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "y_pred = cross_val_predict(sgd_clf, X_train_scale, y_train, cv=5, n_jobs=-1)\n",
    "confusion = confusion_matrix(y_train, y_pred)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示以及标准化\n",
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(confusion, cmap=plt.cm.gray)  # 显示正确的分类数\n",
    "# 每一类除以相应类别总数。比较错误率，而不是绝对的错误数，这对大的类别不公平\n",
    "row_sum = confusion.sum(axis=1, keepdims=True)\n",
    "norm_conf = confusion / row_sum.astype(np.float64)  \n",
    "np.fill_diagonal(norm_conf, 0)\n",
    "plt.matshow(norm_conf, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多标签分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# 多标签k邻近, ML-kNN, 得到距离它最近的k个实例，得到这些实例的标签集合，通过最大后验概率准则来确定新实例的标签集合\n",
    "y_multi_label = np.c_[y_train >= 7, np.bitwise_and(y_train.astype(np.int8), 1)]\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train_scale, y_multi_label)\n",
    "knn_clf.predict([X[62000]]), y[62000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多输出分类 （去噪）\n",
    "from matplotlib.pyplot import matshow, imshow\n",
    "# 加噪\n",
    "noise = np.random.randint(0, 100, size=X_train.shape)\n",
    "X_noise_train = X_train + noise\n",
    "y_noise_train = X_train\n",
    "# 去噪\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_noise_train, y_noise_train)\n",
    "# 做图\n",
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(12, 8))\n",
    "idx = 36000\n",
    "combine = zip([X_noise_train[idx], y_noise_train[idx], knn_clf.predict([X_noise_train[idx]])], [\"train\", \"label\", \"predict\"])\n",
    "for i, (data, label) in enumerate(combine):\n",
    "    ax[i].imshow(data.reshape(28,28), cmap=plt.cm.gray)\n",
    "    ax[i].set_xlabel(label)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
